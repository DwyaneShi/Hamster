#!/bin/bash
#############################################################################
#  Copyright (C) 2016
#  
#  Hamster is free software; you can redistribute it and/or modify it
#  under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  Hamster is distributed in the hope that it will be useful, but
#  WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#  General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with Hamster.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################

# This script is the core 'decommissionhdfsnodes' script.  For the
# most part, it shouldn't be edited.  See job submission files for
# configuration details.

source ${HAMSTER_SCRIPTS_HOME}/lib/hamster-lib-hadoop-helper
source ${HAMSTER_SCRIPTS_HOME}/lib/hamster-lib-paths

# This is a job, no loading export files or libs except for minimal convenience ones

if [ "${HADOOP_DECOMMISSION_HDFS_NODE_SIZE}" -ge "${HADOOP_SLAVE_COUNT}" ]
then
    echo "Cannot decommission more nodes than are available"
    exit 1
fi

cd ${HADOOP_HOME}

hdfsreplication=`${hadoopcmdprefix}/hdfs getconf -confKey dfs.replication 2> /dev/null`

if [ "${HADOOP_DECOMMISSION_HDFS_NODE_SIZE}" -lt ${hdfsreplication} ]
then
    echo "Cannot have fewer nodes than HDFS replication"
    exit 1
fi

nodecounttodecommission=`expr ${HADOOP_SLAVE_COUNT} - ${HADOOP_DECOMMISSION_HDFS_NODE_SIZE}`

echo "Creating ${HADOOP_CONF_DIR}/hosts-exclude"
tail -n ${nodecounttodecommission} ${HADOOP_CONF_DIR}/hosts-include > ${HADOOP_CONF_DIR}/hosts-exclude

echo "Refreshing nodes in namenode"
${hadoopcmdprefix}/hdfs dfsadmin -refreshNodes

while true 
do
    count=`${hadoopcmdprefix}/hdfs dfsadmin -report | grep 'Decommission Status : Decommissioned' | wc -l`
    if [ ${count} -lt "${nodecounttodecommission}" ]
    then
        echo "Done decommissioning ${count} nodes out of ${nodecounttodecommission} ... sleeping for a bit "
        sleep 30
        continue
    fi

    echo "Decommissioned ${count} nodes"
    break
done

# Sets hamster_networkedhdfspath
Hamster_get_networkedhdfspath

count=0
while [ "${count}" -lt "${nodecounttodecommission}" ]
do
    noderank=`expr ${HADOOP_SLAVE_COUNT} - ${count}`
    rmpath="${hamster_networkedhdfspath}/node-${noderank}"
    echo "Removing path ${rmpath} ..."
    rm -rf ${rmpath}
    count=`expr $count + 1`
done

exit 0
